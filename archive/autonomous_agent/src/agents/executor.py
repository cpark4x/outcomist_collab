"""
Executor Agent: Executes steps from the execution plan and generates artifacts.

This module is responsible for:
- Sequential execution of plan steps
- Tool dispatch and orchestration
- Artifact generation and storage
- Error handling and retry logic
- Status tracking and updates

Contract:
- Inputs: ExecutionPlan, WorkingMemory
- Outputs: List[Artifact]
- Side Effects: Tool execution, memory writes, status updates
"""

import logging
import time
from typing import Any, Callable, Dict, List

from ..core.contracts import (
    Artifact,
    ExecutionPlan,
    Step,
    StepStatus,
    ToolType,
)
from ..core.working_memory import WorkingMemory
from ..tools import code_exec, filesystem, research

logger = logging.getLogger(__name__)


class ExecutionError(Exception):
    """Raised when step execution fails"""

    pass


class ExecutorAgent:
    """
    Executes steps from an execution plan sequentially.

    Design principles:
    - Sequential execution (MVP - no parallelization)
    - Store artifacts after each step
    - Graceful error handling with retries
    - Full auditability via working memory
    """

    def __init__(self, memory: WorkingMemory, max_retries: int = 3):
        self.memory = memory
        self.max_retries = max_retries
        self.tool_registry = self._init_tool_registry()

    def _init_tool_registry(self) -> dict[ToolType, Callable]:
        """Map tool types to their implementations"""
        return {
            ToolType.CODE_EXEC: code_exec.execute,
            ToolType.FILESYSTEM: filesystem.execute,
            ToolType.RESEARCH: research.execute,
        }

    def execute_plan(self, plan: ExecutionPlan) -> List[Artifact]:
        """
        Execute all steps in the plan sequentially.

        Args:
            plan: The execution plan to execute

        Returns:
            List of all artifacts generated

        Raises:
            ExecutionError: If any step fails after retries
        """
        logger.info(f"Starting execution of plan with {len(plan.steps)} steps")
        self.memory.store_plan(plan, status="executing")

        artifacts = []

        try:
            for step in plan.steps:
                logger.info(f"Executing step {step.step_id}: {step.tool.value}")
                artifact = self.execute_step(step)
                artifacts.append(artifact)

            logger.info(f"Plan execution completed. Generated {len(artifacts)} artifacts")
            self.memory.store_plan(plan, status="completed")
            return artifacts

        except Exception as e:
            logger.error(f"Plan execution failed: {str(e)}")
            self.memory.store_plan(plan, status="failed")
            raise

    def execute_step(self, step: Step) -> Artifact:
        """
        Execute a single step with retry logic.

        Args:
            step: The step to execute

        Returns:
            Artifact generated by the step

        Raises:
            ExecutionError: If step fails after all retries
        """
        # Update status to RUNNING
        step.status = StepStatus.RUNNING
        self.memory.update_step_status(step.step_id, StepStatus.RUNNING)

        last_error = None

        for attempt in range(1, self.max_retries + 1):
            try:
                logger.info(f"Step {step.step_id} attempt {attempt}/{self.max_retries}")

                # Execute with timeout
                artifact = self._execute_with_timeout(step)

                # Update status to COMPLETED
                step.status = StepStatus.COMPLETED
                self.memory.update_step_status(
                    step.step_id,
                    StepStatus.COMPLETED,
                    result_artifact_id=artifact.artifact_id,
                )

                logger.info(f"Step {step.step_id} completed successfully")
                return artifact

            except Exception as e:
                last_error = e
                logger.warning(f"Step {step.step_id} attempt {attempt} failed: {str(e)}")

                if attempt < self.max_retries:
                    # Exponential backoff
                    backoff = 2**attempt
                    logger.info(f"Retrying in {backoff} seconds...")
                    time.sleep(backoff)

        # All retries exhausted
        step.status = StepStatus.FAILED
        error_msg = f"Step failed after {self.max_retries} attempts: {str(last_error)}"
        self.memory.update_step_status(step.step_id, StepStatus.FAILED, error=error_msg)
        logger.error(f"Step {step.step_id} failed permanently: {error_msg}")
        raise ExecutionError(error_msg)

    def _execute_with_timeout(self, step: Step) -> Artifact:
        """
        Execute a step with timeout enforcement.

        Args:
            step: The step to execute

        Returns:
            Artifact generated by execution

        Raises:
            TimeoutError: If execution exceeds step.timeout
            ExecutionError: If tool execution fails
        """
        start_time = time.time()

        # Dispatch to appropriate tool
        if step.tool not in self.tool_registry:
            raise ExecutionError(f"Unknown tool type: {step.tool}")

        tool_func = self.tool_registry[step.tool]

        try:
            # Resolve variable references in inputs
            resolved_inputs = self._resolve_step_inputs(step)

            # Execute tool
            logger.debug(f"Dispatching to tool: {step.tool.value}")
            result = tool_func(resolved_inputs, self.memory)

            # Check timeout
            elapsed = time.time() - start_time
            if elapsed > step.timeout:
                raise TimeoutError(f"Step exceeded timeout of {step.timeout}s (took {elapsed:.1f}s)")

            # Create artifact
            artifact = self._create_artifact(step, result)

            # Store in memory
            artifact_id = self.memory.store_artifact(artifact)
            artifact.artifact_id = artifact_id

            logger.debug(f"Step {step.step_id} generated artifact {artifact_id} in {elapsed:.2f}s")

            return artifact

        except Exception as e:
            logger.error(f"Tool execution failed for {step.tool.value}: {str(e)}")
            raise ExecutionError(f"Tool execution failed: {str(e)}") from e

    def _resolve_step_inputs(self, step: Step) -> Dict[str, Any]:
        """
        Resolve variable references in step inputs from previous step outputs.

        Handles patterns like:
        - "<FROM_STEP_1_html_content>" -> retrieves 'html_content' variable from step_1's code_exec result
        - Regular values are passed through unchanged

        Args:
            step: The step whose inputs need resolution

        Returns:
            Resolved inputs dictionary with variables substituted
        """
        import re

        resolved = step.inputs.copy()

        # Pattern to match variable references: <FROM_STEP_X_varname>
        var_pattern = re.compile(r"<FROM_STEP_(\w+)_(\w+)>")

        def resolve_value(value):
            """Recursively resolve references in a value"""
            if isinstance(value, str):
                # Check for variable reference
                match = var_pattern.match(value.strip())
                if match:
                    step_number = match.group(1)
                    var_name = match.group(2)

                    # Convert to actual step_id format (step_1, step_2, etc.)
                    dep_step_id = f"step_{step_number}"

                    # Get the dependency step's artifact
                    dep_status = self.memory.get_step_status(dep_step_id)
                    if dep_status and dep_status.get("result_artifact_id"):
                        dep_artifact = self.memory.get_artifact(dep_status["result_artifact_id"])
                        if dep_artifact:
                            # Extract variable from code_exec result
                            content = dep_artifact.content
                            if isinstance(content, dict):
                                # Check in variables dict first
                                if "variables" in content and var_name in content["variables"]:
                                    logger.info(f"Resolved {var_name} from {dep_step_id}")
                                    return content["variables"][var_name]
                                # Fall back to result
                                elif "result" in content:
                                    return content.get("result", value)
                                # Check top-level
                                elif var_name in content:
                                    return content[var_name]

                    logger.warning(f"Could not resolve variable reference: {value}")
                    return value
                return value
            elif isinstance(value, dict):
                return {k: resolve_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [resolve_value(v) for v in value]
            return value

        # Resolve all values in inputs
        for key, value in resolved.items():
            resolved[key] = resolve_value(value)

        return resolved

    def _create_artifact(self, step: Step, result: Any) -> Artifact:
        """
        Create an artifact from step execution result.

        Args:
            step: The step that was executed
            result: The result from tool execution

        Returns:
            Artifact containing the result
        """
        # Determine content type from result
        if isinstance(result, dict) and "content_type" in result:
            content = result.get("content", result)
            content_type = result["content_type"]
        elif isinstance(result, str):
            content = result
            content_type = "text"
        elif isinstance(result, (dict, list)):
            content = result
            content_type = "json"
        else:
            content = str(result)
            content_type = "text"

        # Build provenance chain
        provenance = [step.step_id]

        # Get dependencies' artifacts to extend provenance
        for dep_step_id in step.dependencies:
            dep_status = self.memory.get_step_status(dep_step_id)
            if dep_status and dep_status.get("result_artifact_id"):
                dep_artifact = self.memory.get_artifact(dep_status["result_artifact_id"])
                if dep_artifact:
                    provenance.extend(dep_artifact.provenance)

        return Artifact(
            artifact_id="",  # Will be set when stored
            content=content,
            content_type=content_type,
            created_by=step.step_id,
            metadata={
                "tool": step.tool.value,
                "inputs": step.inputs,
                "expected_output": step.expected_output,
            },
            provenance=provenance,
        )

    def execute_ready_steps(self, plan: ExecutionPlan) -> List[Artifact]:
        """
        Execute all steps that are ready (dependencies met).

        This enables dependency-aware execution without explicit parallelization.

        Args:
            plan: The execution plan

        Returns:
            List of artifacts generated from ready steps
        """
        artifacts = []
        ready_steps = plan.get_ready_steps()

        logger.info(f"Found {len(ready_steps)} ready steps to execute")

        for step in ready_steps:
            try:
                artifact = self.execute_step(step)
                artifacts.append(artifact)
            except ExecutionError as e:
                logger.error(f"Step {step.step_id} failed: {str(e)}")
                # Continue with other steps (fail-gracefully pattern)
                continue

        return artifacts
